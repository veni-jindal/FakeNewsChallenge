{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_FNC.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqlcFExp06jA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "adc44695-bc61-4773-ad68-fae35b90a6c1"
      },
      "source": [
        "!git clone https://github.com/veni-jindal/FakeNewsChallenge.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'FakeNewsChallenge' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT_PysUs08Ml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "df6f080e-0491-4fc0-9093-47155b4cd8ee"
      },
      "source": [
        "# importing required packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from csv import DictReader\n",
        "import re\n",
        "import nltk\n",
        "from sklearn import feature_extraction\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "_wnl = nltk.WordNetLemmatizer()\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcNnWU-pWMIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install --upgrade tb-nightly"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPBOPY-ta8b2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing required packages\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from datetime import datetime"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtDl78OMa7vb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3d15bc57-8163-4b23-a53f-0c6da2f8f4e1"
      },
      "source": [
        "# installing bert-tensorflow\n",
        "!pip install bert-tensorflow==1.0.1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-tensorflow==1.0.1 in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow==1.0.1) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3a3cMVYdgzb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b05f2ed1-6050-4c24-cd8d-a690520e2e66"
      },
      "source": [
        "# setting the tensorflow version 1.x\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTtMUAWQdBcq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "8ac1f9c1-3095-420b-ce4a-4542825b51bc"
      },
      "source": [
        "# importing bert \n",
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0VJCBNq1lC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to read the stances & bodies file\n",
        "class DataSet():\n",
        "    def __init__(self, name, path=\"FakeNewsChallenge/fnc-1\"):\n",
        "        self.path = path\n",
        "\n",
        "        print(\"Reading train dataset\")\n",
        "        bodies = name+\"_bodies.csv\"\n",
        "        stances = name+\"_stances.csv\"\n",
        "        print(stances)\n",
        "\n",
        "        self.stances = self.read(stances)\n",
        "        articles = self.read(bodies)\n",
        "        self.articles = dict()\n",
        "\n",
        "        #make the body ID an integer value\n",
        "        for s in self.stances:\n",
        "            s['Body ID'] = int(s['Body ID'])\n",
        "\n",
        "        #copy all bodies into a dictionary\n",
        "        for article in articles:\n",
        "            self.articles[int(article['Body ID'])] = article['articleBody']\n",
        "\n",
        "        print(\"Total stances: \" + str(len(self.stances)))\n",
        "        print(\"Total bodies: \" + str(len(self.articles)))\n",
        "    \n",
        "    def read(self,filename):\n",
        "        rows = []\n",
        "        with open(self.path + \"/\" + filename, \"r\", encoding='utf-8') as table:\n",
        "            r = DictReader(table)\n",
        "\n",
        "            for line in r:\n",
        "                rows.append(line)\n",
        "        return rows"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn8p3t2U3s1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting the root word\n",
        "def normalize_word(w):\n",
        "    return _wnl.lemmatize(w).lower()\n",
        "\n",
        "# tokenisation and lowering the text\n",
        "def get_tokenized_lemmas(s):\n",
        "    return [normalize_word(t) for t in nltk.word_tokenize(s)]\n",
        "\n",
        "# Cleans a string: Lowercasing, trimming, removing non-alphanumeric\n",
        "def clean(s):  \n",
        "    return \" \".join(re.findall(r'\\w+', s, flags=re.UNICODE)).lower()\n",
        "\n",
        "# Removes stopwords from a list of tokens\n",
        "def remove_stopwords(l):\n",
        "    return [w for w in l if w not in feature_extraction.text.ENGLISH_STOP_WORDS]\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRFqnHLS2bSN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "a3004cea-145c-4d76-ddcd-655963fa7c2d"
      },
      "source": [
        "# getting train dataset\n",
        "train = DataSet(\"train\")\n",
        "# getting test dataset\n",
        "test = DataSet(\"competition_test\")\n",
        "# labels list\n",
        "LABELS = ['agree', 'disagree', 'discuss', 'unrelated']\n",
        "# labels - Related/Unrelated\n",
        "LABELS_RELATED = ['unrelated','related']\n",
        "# Getting the labels belonging to related category\n",
        "RELATED = LABELS[0:3]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading train dataset\n",
            "train_stances.csv\n",
            "Total stances: 49972\n",
            "Total bodies: 1683\n",
            "Reading train dataset\n",
            "competition_test_stances.csv\n",
            "Total stances: 25413\n",
            "Total bodies: 904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMsFhnTNgzSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# label list\n",
        "label_list = [0,1,2,3]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yDN2uyU8mc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# headlines\n",
        "h = []\n",
        "h_test = []\n",
        "# labels for stance\n",
        "y = []\n",
        "y_test = []\n",
        "# body text\n",
        "b = []\n",
        "b_test = []\n",
        "for s in train.stances:\n",
        "  h.append(s['Headline'])\n",
        "  b.append(train.articles[s['Body ID']])\n",
        "  y.append(LABELS.index(s['Stance']))\n",
        "\n",
        "for s in test.stances:\n",
        "  h_test.append(s['Headline'])\n",
        "  b_test.append(test.articles[s['Body ID']])\n",
        "  y_test.append(LABELS.index(s['Stance']))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA8bdkfZ5v6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train dataframe\n",
        "train_df = pd.DataFrame(columns=['head','body', 'labels'])\n",
        "train_df['head'] = h\n",
        "train_df['body'] = b\n",
        "train_df['labels'] = y"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7S3b5F4q8jDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test dataframe\n",
        "test_df = pd.DataFrame(columns=['head','body', 'labels'])\n",
        "test_df['head'] = h_test\n",
        "test_df['body'] = b_test\n",
        "test_df['labels'] = y_test"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uXUvnKOfXW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
        "train_InputExamples = train_df.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x['head'], \n",
        "                                                                   text_b = x['body'], \n",
        "                                                                   label = x['labels']), axis = 1)\n",
        "\n",
        "test_InputExamples = test_df.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x['head'], \n",
        "                                                                   text_b = x['body'], \n",
        "                                                                   label = x['labels']), axis = 1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUF48YelfnEF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "feaf636a-2177-487f-af30-f7e8240ad493"
      },
      "source": [
        "# This is a path to an uncased (all lowercase) version of BERT\n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8rJMbnTgL_b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c809a332-3355-4e00-a578-575ed7714df1"
      },
      "source": [
        "# max sequence length\n",
        "MAX_SEQ_LENGTH = 128\n",
        "# Convert our train and test features to InputFeatures that BERT understands.\n",
        "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 49972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 49972\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] police find mass graves with at least ' 15 bodies ' near mexico town where 43 students disappeared after police clash [SEP] danny boyle is directing the untitled film seth ro ##gen is being eyed to play apple co - founder steve wo ##z ##nia ##k in sony ’ s steve jobs bio ##pic . danny boyle is directing the untitled film , based on walter isaac ##son ' s book and adapted by aaron so ##rkin , which is one of the most anticipated bio ##pic ##s in recent years . negotiations have not yet begun , and it ’ s not even clear if ro ##gen has an official offer , but the producers — scott ru ##din , guy ##mon casa ##dy and [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] police find mass graves with at least ' 15 bodies ' near mexico town where 43 students disappeared after police clash [SEP] danny boyle is directing the untitled film seth ro ##gen is being eyed to play apple co - founder steve wo ##z ##nia ##k in sony ’ s steve jobs bio ##pic . danny boyle is directing the untitled film , based on walter isaac ##son ' s book and adapted by aaron so ##rkin , which is one of the most anticipated bio ##pic ##s in recent years . negotiations have not yet begun , and it ’ s not even clear if ro ##gen has an official offer , but the producers — scott ru ##din , guy ##mon casa ##dy and [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2610 2424 3742 9729 2007 2012 2560 1005 2321 4230 1005 2379 3290 2237 2073 4724 2493 5419 2044 2610 13249 102 6266 16694 2003 9855 1996 24819 2143 6662 20996 6914 2003 2108 7168 2000 2377 6207 2522 1011 3910 3889 24185 2480 6200 2243 1999 8412 1521 1055 3889 5841 16012 24330 1012 6266 16694 2003 9855 1996 24819 2143 1010 2241 2006 4787 7527 3385 1005 1055 2338 1998 5967 2011 7158 2061 26891 1010 2029 2003 2028 1997 1996 2087 11436 16012 24330 2015 1999 3522 2086 1012 7776 2031 2025 2664 5625 1010 1998 2009 1521 1055 2025 2130 3154 2065 20996 6914 2038 2019 2880 3749 1010 2021 1996 6443 1517 3660 21766 8718 1010 3124 8202 14124 5149 1998 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2610 2424 3742 9729 2007 2012 2560 1005 2321 4230 1005 2379 3290 2237 2073 4724 2493 5419 2044 2610 13249 102 6266 16694 2003 9855 1996 24819 2143 6662 20996 6914 2003 2108 7168 2000 2377 6207 2522 1011 3910 3889 24185 2480 6200 2243 1999 8412 1521 1055 3889 5841 16012 24330 1012 6266 16694 2003 9855 1996 24819 2143 1010 2241 2006 4787 7527 3385 1005 1055 2338 1998 5967 2011 7158 2061 26891 1010 2029 2003 2028 1997 1996 2087 11436 16012 24330 2015 1999 3522 2086 1012 7776 2031 2025 2664 5625 1010 1998 2009 1521 1055 2025 2130 3154 2065 20996 6914 2038 2019 2880 3749 1010 2021 1996 6443 1517 3660 21766 8718 1010 3124 8202 14124 5149 1998 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 3 (id = 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 3 (id = 3)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] hundreds of palestinians flee floods in gaza as israel opens dams [SEP] hundreds of palestinians were evacuated from their homes sunday morning after israeli authorities opened a number of dams near the border , flooding the gaza valley in the wake of a recent severe winter storm . the gaza ministry of interior said in a statement that civil defense services and teams from the ministry of public works had evacuated more than 80 families from both sides of the gaza valley ( wadi gaza ) after their homes flooded as water levels reached more than three meters . gaza has experienced flooding in recent days amid a major storm that saw temperatures drop and fr ##ig ##id rain pour down . the storm displaced dozens [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] hundreds of palestinians flee floods in gaza as israel opens dams [SEP] hundreds of palestinians were evacuated from their homes sunday morning after israeli authorities opened a number of dams near the border , flooding the gaza valley in the wake of a recent severe winter storm . the gaza ministry of interior said in a statement that civil defense services and teams from the ministry of public works had evacuated more than 80 families from both sides of the gaza valley ( wadi gaza ) after their homes flooded as water levels reached more than three meters . gaza has experienced flooding in recent days amid a major storm that saw temperatures drop and fr ##ig ##id rain pour down . the storm displaced dozens [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 5606 1997 21524 10574 14295 1999 14474 2004 3956 7480 17278 102 5606 1997 21524 2020 13377 2013 2037 5014 4465 2851 2044 5611 4614 2441 1037 2193 1997 17278 2379 1996 3675 1010 9451 1996 14474 3028 1999 1996 5256 1997 1037 3522 5729 3467 4040 1012 1996 14474 3757 1997 4592 2056 1999 1037 4861 2008 2942 3639 2578 1998 2780 2013 1996 3757 1997 2270 2573 2018 13377 2062 2084 3770 2945 2013 2119 3903 1997 1996 14474 3028 1006 28380 14474 1007 2044 2037 5014 10361 2004 2300 3798 2584 2062 2084 2093 5563 1012 14474 2038 5281 9451 1999 3522 2420 13463 1037 2350 4040 2008 2387 7715 4530 1998 10424 8004 3593 4542 10364 2091 1012 1996 4040 12936 9877 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 5606 1997 21524 10574 14295 1999 14474 2004 3956 7480 17278 102 5606 1997 21524 2020 13377 2013 2037 5014 4465 2851 2044 5611 4614 2441 1037 2193 1997 17278 2379 1996 3675 1010 9451 1996 14474 3028 1999 1996 5256 1997 1037 3522 5729 3467 4040 1012 1996 14474 3757 1997 4592 2056 1999 1037 4861 2008 2942 3639 2578 1998 2780 2013 1996 3757 1997 2270 2573 2018 13377 2062 2084 3770 2945 2013 2119 3903 1997 1996 14474 3028 1006 28380 14474 1007 2044 2037 5014 10361 2004 2300 3798 2584 2062 2084 2093 5563 1012 14474 2038 5281 9451 1999 3522 2420 13463 1037 2350 4040 2008 2387 7715 4530 1998 10424 8004 3593 4542 10364 2091 1012 1996 4040 12936 9877 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] christian bal ##e passes on role of steve jobs , actor reportedly felt he wasn ' t right for part [SEP] 30 - year - old moscow resident was hospitalized with wounds very intimate nature . as it became known life ##ne ##ws , in the hands of doctors , the man complained that his casual acquaintance op ##oi ##la in the sa ##una , and then gently held his cast ##ration operation . and actions criminals were executed with surgical precision - woman se ##wed all the smallest blood vessels . - i met a girl at the bar , and then we went to the sa ##una for a taxi . i remember that i had a beer , and more do not remember [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] christian bal ##e passes on role of steve jobs , actor reportedly felt he wasn ' t right for part [SEP] 30 - year - old moscow resident was hospitalized with wounds very intimate nature . as it became known life ##ne ##ws , in the hands of doctors , the man complained that his casual acquaintance op ##oi ##la in the sa ##una , and then gently held his cast ##ration operation . and actions criminals were executed with surgical precision - woman se ##wed all the smallest blood vessels . - i met a girl at the bar , and then we went to the sa ##una for a taxi . i remember that i had a beer , and more do not remember [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3017 28352 2063 5235 2006 2535 1997 3889 5841 1010 3364 7283 2371 2002 2347 1005 1056 2157 2005 2112 102 2382 1011 2095 1011 2214 4924 6319 2001 24735 2007 8710 2200 10305 3267 1012 2004 2009 2150 2124 2166 2638 9333 1010 1999 1996 2398 1997 7435 1010 1996 2158 10865 2008 2010 10017 18363 6728 10448 2721 1999 1996 7842 9521 1010 1998 2059 5251 2218 2010 3459 8156 3169 1012 1998 4506 12290 2020 6472 2007 11707 11718 1011 2450 7367 15557 2035 1996 10479 2668 6470 1012 1011 1045 2777 1037 2611 2012 1996 3347 1010 1998 2059 2057 2253 2000 1996 7842 9521 2005 1037 10095 1012 1045 3342 2008 1045 2018 1037 5404 1010 1998 2062 2079 2025 3342 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3017 28352 2063 5235 2006 2535 1997 3889 5841 1010 3364 7283 2371 2002 2347 1005 1056 2157 2005 2112 102 2382 1011 2095 1011 2214 4924 6319 2001 24735 2007 8710 2200 10305 3267 1012 2004 2009 2150 2124 2166 2638 9333 1010 1999 1996 2398 1997 7435 1010 1996 2158 10865 2008 2010 10017 18363 6728 10448 2721 1999 1996 7842 9521 1010 1998 2059 5251 2218 2010 3459 8156 3169 1012 1998 4506 12290 2020 6472 2007 11707 11718 1011 2450 7367 15557 2035 1996 10479 2668 6470 1012 1011 1045 2777 1037 2611 2012 1996 3347 1010 1998 2059 2057 2253 2000 1996 7842 9521 2005 1037 10095 1012 1045 3342 2008 1045 2018 1037 5404 1010 1998 2062 2079 2025 3342 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 3 (id = 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 3 (id = 3)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] hbo and apple in talks for $ 15 / month apple tv streaming service launching in april [SEP] ( reuters ) - a canadian soldier was shot at the canadian war memorial in ottawa and a shooter was seen running towards the nearby parliament buildings where more shots were fired , according to multiple media and eye ##wi ##tness reports on wednesday . the buildings were put in lock ##down as police and tactical teams converge ##d on the area . the shooting comes two days after an islamic convert ran down two canadian soldiers , killing one , near montreal . ( reporting by andrea hopkins ; editing by am ##ran ab ##oca ##r ) [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] hbo and apple in talks for $ 15 / month apple tv streaming service launching in april [SEP] ( reuters ) - a canadian soldier was shot at the canadian war memorial in ottawa and a shooter was seen running towards the nearby parliament buildings where more shots were fired , according to multiple media and eye ##wi ##tness reports on wednesday . the buildings were put in lock ##down as police and tactical teams converge ##d on the area . the shooting comes two days after an islamic convert ran down two canadian soldiers , killing one , near montreal . ( reporting by andrea hopkins ; editing by am ##ran ab ##oca ##r ) [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 14633 1998 6207 1999 7566 2005 1002 2321 1013 3204 6207 2694 11058 2326 12106 1999 2258 102 1006 26665 1007 1011 1037 3010 5268 2001 2915 2012 1996 3010 2162 3986 1999 8166 1998 1037 13108 2001 2464 2770 2875 1996 3518 3323 3121 2073 2062 7171 2020 5045 1010 2429 2000 3674 2865 1998 3239 9148 27401 4311 2006 9317 1012 1996 3121 2020 2404 1999 5843 7698 2004 2610 1998 8608 2780 28314 2094 2006 1996 2181 1012 1996 5008 3310 2048 2420 2044 2019 5499 10463 2743 2091 2048 3010 3548 1010 4288 2028 1010 2379 5548 1012 1006 7316 2011 8657 10239 1025 9260 2011 2572 5521 11113 24755 2099 1007 102 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 14633 1998 6207 1999 7566 2005 1002 2321 1013 3204 6207 2694 11058 2326 12106 1999 2258 102 1006 26665 1007 1011 1037 3010 5268 2001 2915 2012 1996 3010 2162 3986 1999 8166 1998 1037 13108 2001 2464 2770 2875 1996 3518 3323 3121 2073 2062 7171 2020 5045 1010 2429 2000 3674 2865 1998 3239 9148 27401 4311 2006 9317 1012 1996 3121 2020 2404 1999 5843 7698 2004 2610 1998 8608 2780 28314 2094 2006 1996 2181 1012 1996 5008 3310 2048 2420 2044 2019 5499 10463 2743 2091 2048 3010 3548 1010 4288 2028 1010 2379 5548 1012 1006 7316 2011 8657 10239 1025 9260 2011 2572 5521 11113 24755 2099 1007 102 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 3 (id = 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 3 (id = 3)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] spider burr ##owed through tourist ' s stomach and up into his chest [SEP] fear not ara ##ch ##no ##ph ##obe ##s , the story of bun ##bury ' s \" spider ##man \" might not be all it seemed . perth scientists have cast doubt over claims that a spider burr ##owed into a man ' s body during his first trip to bali . the story went global on thursday , generating hundreds of stories online . earlier this month , dylan thomas headed to the holiday island and sought medical help after experiencing \" a really burning sensation like a searing feeling \" in his abdomen . dylan thomas says he had a spider crawl underneath his skin . thomas said a specialist [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] spider burr ##owed through tourist ' s stomach and up into his chest [SEP] fear not ara ##ch ##no ##ph ##obe ##s , the story of bun ##bury ' s \" spider ##man \" might not be all it seemed . perth scientists have cast doubt over claims that a spider burr ##owed into a man ' s body during his first trip to bali . the story went global on thursday , generating hundreds of stories online . earlier this month , dylan thomas headed to the holiday island and sought medical help after experiencing \" a really burning sensation like a searing feeling \" in his abdomen . dylan thomas says he had a spider crawl underneath his skin . thomas said a specialist [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 6804 22715 15096 2083 7538 1005 1055 4308 1998 2039 2046 2010 3108 102 3571 2025 19027 2818 3630 8458 20891 2015 1010 1996 2466 1997 21122 4917 1005 1055 1000 6804 2386 1000 2453 2025 2022 2035 2009 2790 1012 9300 6529 2031 3459 4797 2058 4447 2008 1037 6804 22715 15096 2046 1037 2158 1005 1055 2303 2076 2010 2034 4440 2000 20222 1012 1996 2466 2253 3795 2006 9432 1010 11717 5606 1997 3441 3784 1012 3041 2023 3204 1010 7758 2726 3753 2000 1996 6209 2479 1998 4912 2966 2393 2044 13417 1000 1037 2428 5255 8742 2066 1037 25764 3110 1000 1999 2010 13878 1012 7758 2726 2758 2002 2018 1037 6804 13529 7650 2010 3096 1012 2726 2056 1037 8325 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 6804 22715 15096 2083 7538 1005 1055 4308 1998 2039 2046 2010 3108 102 3571 2025 19027 2818 3630 8458 20891 2015 1010 1996 2466 1997 21122 4917 1005 1055 1000 6804 2386 1000 2453 2025 2022 2035 2009 2790 1012 9300 6529 2031 3459 4797 2058 4447 2008 1037 6804 22715 15096 2046 1037 2158 1005 1055 2303 2076 2010 2034 4440 2000 20222 1012 1996 2466 2253 3795 2006 9432 1010 11717 5606 1997 3441 3784 1012 3041 2023 3204 1010 7758 2726 3753 2000 1996 6209 2479 1998 4912 2966 2393 2044 13417 1000 1037 2428 5255 8742 2066 1037 25764 3110 1000 1999 2010 13878 1012 7758 2726 2758 2002 2018 1037 6804 13529 7650 2010 3096 1012 2726 2056 1037 8325 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 49972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 49972\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 49972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 49972\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 30000 of 49972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 30000 of 49972\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 40000 of 49972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 40000 of 49972\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 25413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 25413\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] ferguson riots : pregnant woman loses eye after cops fire bean bag round through car window [SEP] a respected senior french police officer investigating the charlie he ##b ##do magazine massacre took his own life mere hours after the horrific attacks stunned the world . commissioner he ##lr ##ic fred ##ou , 45 , turned a gun on himself in his police office in limo ##ges last wednesday night , reported france 3 . a colleague found his body at 1a ##m on thursday , the day after three gunmen fired at the satirical magazine ' s office and left 12 people dead . speaking to our sister publication mirror online , the union of commissioners of the national police confirmed mr fred ##ou had taken [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] ferguson riots : pregnant woman loses eye after cops fire bean bag round through car window [SEP] a respected senior french police officer investigating the charlie he ##b ##do magazine massacre took his own life mere hours after the horrific attacks stunned the world . commissioner he ##lr ##ic fred ##ou , 45 , turned a gun on himself in his police office in limo ##ges last wednesday night , reported france 3 . a colleague found his body at 1a ##m on thursday , the day after three gunmen fired at the satirical magazine ' s office and left 12 people dead . speaking to our sister publication mirror online , the union of commissioners of the national police confirmed mr fred ##ou had taken [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 11262 12925 1024 6875 2450 12386 3239 2044 10558 2543 14068 4524 2461 2083 2482 3332 102 1037 9768 3026 2413 2610 2961 11538 1996 4918 2002 2497 3527 2932 9288 2165 2010 2219 2166 8210 2847 2044 1996 23512 4491 9860 1996 2088 1012 5849 2002 20974 2594 5965 7140 1010 3429 1010 2357 1037 3282 2006 2370 1999 2010 2610 2436 1999 23338 8449 2197 9317 2305 1010 2988 2605 1017 1012 1037 11729 2179 2010 2303 2012 20720 2213 2006 9432 1010 1996 2154 2044 2093 28932 5045 2012 1996 17251 2932 1005 1055 2436 1998 2187 2260 2111 2757 1012 4092 2000 2256 2905 4772 5259 3784 1010 1996 2586 1997 12396 1997 1996 2120 2610 4484 2720 5965 7140 2018 2579 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 11262 12925 1024 6875 2450 12386 3239 2044 10558 2543 14068 4524 2461 2083 2482 3332 102 1037 9768 3026 2413 2610 2961 11538 1996 4918 2002 2497 3527 2932 9288 2165 2010 2219 2166 8210 2847 2044 1996 23512 4491 9860 1996 2088 1012 5849 2002 20974 2594 5965 7140 1010 3429 1010 2357 1037 3282 2006 2370 1999 2010 2610 2436 1999 23338 8449 2197 9317 2305 1010 2988 2605 1017 1012 1037 11729 2179 2010 2303 2012 20720 2213 2006 9432 1010 1996 2154 2044 2093 28932 5045 2012 1996 17251 2932 1005 1055 2436 1998 2187 2260 2111 2757 1012 4092 2000 2256 2905 4772 5259 3784 1010 1996 2586 1997 12396 1997 1996 2120 2610 4484 2720 5965 7140 2018 2579 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 3 (id = 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 3 (id = 3)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] crazy conservatives are sure a gi ##tm ##o det ##aine ##e killed james foley [SEP] dave mori ##n ' s social networking company path is reportedly in apple inc . ' s acquisition path . apple inc . is close to buying social network path as it aims to bo ##lster its social media efforts , pan ##do ##dai ##ly reported , citing an internal source on apple ' s engineering team . the purchase would be more than an ac ##qui ##hire , the process when a company buys a company for its talent rather than its product . path ' s platform will probably survive the acquisition and somehow be incorporated into apple ' s rev ##amp ##ed messages app , according to the [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] crazy conservatives are sure a gi ##tm ##o det ##aine ##e killed james foley [SEP] dave mori ##n ' s social networking company path is reportedly in apple inc . ' s acquisition path . apple inc . is close to buying social network path as it aims to bo ##lster its social media efforts , pan ##do ##dai ##ly reported , citing an internal source on apple ' s engineering team . the purchase would be more than an ac ##qui ##hire , the process when a company buys a company for its talent rather than its product . path ' s platform will probably survive the acquisition and somehow be incorporated into apple ' s rev ##amp ##ed messages app , according to the [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4689 11992 2024 2469 1037 21025 21246 2080 20010 18175 2063 2730 2508 17106 102 4913 22993 2078 1005 1055 2591 14048 2194 4130 2003 7283 1999 6207 4297 1012 1005 1055 7654 4130 1012 6207 4297 1012 2003 2485 2000 9343 2591 2897 4130 2004 2009 8704 2000 8945 29576 2049 2591 2865 4073 1010 6090 3527 21351 2135 2988 1010 8951 2019 4722 3120 2006 6207 1005 1055 3330 2136 1012 1996 5309 2052 2022 2062 2084 2019 9353 15549 20908 1010 1996 2832 2043 1037 2194 23311 1037 2194 2005 2049 5848 2738 2084 2049 4031 1012 4130 1005 1055 4132 2097 2763 5788 1996 7654 1998 5064 2022 5100 2046 6207 1005 1055 7065 16613 2098 7696 10439 1010 2429 2000 1996 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4689 11992 2024 2469 1037 21025 21246 2080 20010 18175 2063 2730 2508 17106 102 4913 22993 2078 1005 1055 2591 14048 2194 4130 2003 7283 1999 6207 4297 1012 1005 1055 7654 4130 1012 6207 4297 1012 2003 2485 2000 9343 2591 2897 4130 2004 2009 8704 2000 8945 29576 2049 2591 2865 4073 1010 6090 3527 21351 2135 2988 1010 8951 2019 4722 3120 2006 6207 1005 1055 3330 2136 1012 1996 5309 2052 2022 2062 2084 2019 9353 15549 20908 1010 1996 2832 2043 1037 2194 23311 1037 2194 2005 2049 5848 2738 2084 2049 4031 1012 4130 1005 1055 4132 2097 2763 5788 1996 7654 1998 5064 2022 5100 2046 6207 1005 1055 7065 16613 2098 7696 10439 1010 2429 2000 1996 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 3 (id = 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 3 (id = 3)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] a russian guy says his justin bi ##eber ring ##tone saved him from a bear attack [SEP] a be ##rea ##ved afghan mother took revenge on the taliban after watching them kill her son in an ambush . reza gu ##l killed 25 taliban fighters and injured five others in a seven - hour gun ##bat ##tle in far ##ah province . gu ##l , who was joined by her daughter and daughter in - law , engaged the taliban using ak - 47 ##s and grenades , despite ##ne ##ver before having used a weapon . the em ##bat ##tled mother told to ##lo news , a 24 - hour afghan news broadcaster , she was awakened by shots early tuesday . after seeing that [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] a russian guy says his justin bi ##eber ring ##tone saved him from a bear attack [SEP] a be ##rea ##ved afghan mother took revenge on the taliban after watching them kill her son in an ambush . reza gu ##l killed 25 taliban fighters and injured five others in a seven - hour gun ##bat ##tle in far ##ah province . gu ##l , who was joined by her daughter and daughter in - law , engaged the taliban using ak - 47 ##s and grenades , despite ##ne ##ver before having used a weapon . the em ##bat ##tled mother told to ##lo news , a 24 - hour afghan news broadcaster , she was awakened by shots early tuesday . after seeing that [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1037 2845 3124 2758 2010 6796 12170 22669 3614 5524 5552 2032 2013 1037 4562 2886 102 1037 2022 16416 7178 12632 2388 2165 7195 2006 1996 16597 2044 3666 2068 3102 2014 2365 1999 2019 15283 1012 26323 19739 2140 2730 2423 16597 7299 1998 5229 2274 2500 1999 1037 2698 1011 3178 3282 14479 9286 1999 2521 4430 2874 1012 19739 2140 1010 2040 2001 2587 2011 2014 2684 1998 2684 1999 1011 2375 1010 5117 1996 16597 2478 17712 1011 4700 2015 1998 21914 1010 2750 2638 6299 2077 2383 2109 1037 5195 1012 1996 7861 14479 14782 2388 2409 2000 4135 2739 1010 1037 2484 1011 3178 12632 2739 11995 1010 2016 2001 20256 2011 7171 2220 9857 1012 2044 3773 2008 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1037 2845 3124 2758 2010 6796 12170 22669 3614 5524 5552 2032 2013 1037 4562 2886 102 1037 2022 16416 7178 12632 2388 2165 7195 2006 1996 16597 2044 3666 2068 3102 2014 2365 1999 2019 15283 1012 26323 19739 2140 2730 2423 16597 7299 1998 5229 2274 2500 1999 1037 2698 1011 3178 3282 14479 9286 1999 2521 4430 2874 1012 19739 2140 1010 2040 2001 2587 2011 2014 2684 1998 2684 1999 1011 2375 1010 5117 1996 16597 2478 17712 1011 4700 2015 1998 21914 1010 2750 2638 6299 2077 2383 2109 1037 5195 1012 1996 7861 14479 14782 2388 2409 2000 4135 2739 1010 1037 2484 1011 3178 12632 2739 11995 1010 2016 2001 20256 2011 7171 2220 9857 1012 2044 3773 2008 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 3 (id = 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 3 (id = 3)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] zombie cat : buried kitty believed dead , me ##ows back to life [SEP] he ##wl ##ett - packard is officially splitting in two . following rumors over the weekend , hp is announcing today that it will separate its pc and printer division from its enterprise and services business . the split means current ceo meg whitman will become the chairman of the pc and printer operation , and continue as ceo of the split - off enterprise business . dion wei ##sler , an executive at hp ’ s pc business , will take over as ceo of the company ’ s pc and printer operation . hp enterprise is the newly split - off part of the original company , and hp inc [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] zombie cat : buried kitty believed dead , me ##ows back to life [SEP] he ##wl ##ett - packard is officially splitting in two . following rumors over the weekend , hp is announcing today that it will separate its pc and printer division from its enterprise and services business . the split means current ceo meg whitman will become the chairman of the pc and printer operation , and continue as ceo of the split - off enterprise business . dion wei ##sler , an executive at hp ’ s pc business , will take over as ceo of the company ’ s pc and printer operation . hp enterprise is the newly split - off part of the original company , and hp inc [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 11798 4937 1024 3950 14433 3373 2757 1010 2033 15568 2067 2000 2166 102 2002 13668 6582 1011 24100 2003 3985 14541 1999 2048 1012 2206 11256 2058 1996 5353 1010 6522 2003 13856 2651 2008 2009 2097 3584 2049 7473 1998 15041 2407 2013 2049 6960 1998 2578 2449 1012 1996 3975 2965 2783 5766 12669 21311 2097 2468 1996 3472 1997 1996 7473 1998 15041 3169 1010 1998 3613 2004 5766 1997 1996 3975 1011 2125 6960 2449 1012 19542 11417 20590 1010 2019 3237 2012 6522 1521 1055 7473 2449 1010 2097 2202 2058 2004 5766 1997 1996 2194 1521 1055 7473 1998 15041 3169 1012 6522 6960 2003 1996 4397 3975 1011 2125 2112 1997 1996 2434 2194 1010 1998 6522 4297 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 11798 4937 1024 3950 14433 3373 2757 1010 2033 15568 2067 2000 2166 102 2002 13668 6582 1011 24100 2003 3985 14541 1999 2048 1012 2206 11256 2058 1996 5353 1010 6522 2003 13856 2651 2008 2009 2097 3584 2049 7473 1998 15041 2407 2013 2049 6960 1998 2578 2449 1012 1996 3975 2965 2783 5766 12669 21311 2097 2468 1996 3472 1997 1996 7473 1998 15041 3169 1010 1998 3613 2004 5766 1997 1996 3975 1011 2125 6960 2449 1012 19542 11417 20590 1010 2019 3237 2012 6522 1521 1055 7473 2449 1010 2097 2202 2058 2004 5766 1997 1996 2194 1521 1055 7473 1998 15041 3169 1012 6522 6960 2003 1996 4397 3975 1011 2125 2112 1997 1996 2434 2194 1010 1998 6522 4297 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 3 (id = 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 3 (id = 3)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] argentina ' s president adopt ##s boy to end werewolf curse [SEP] an airline passenger headed to dallas was removed from a plane at la guard ##ia airport on christmas eve because he raged after workers wished him a merry christmas , the new york post reports . the man was waiting to board american airlines flight 114 ##0 to dallas when a gate agent began welcoming everyone with the yu ##let ##ide greeting . he yelled at the woman , “ you shouldn ’ t say that because not everyone celebrates christmas . ” once on the plane , a flight attendant wished him a “ merry christmas . ” he yelled , “ don ’ t say , ‘ merry christmas ! ’ ” [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] argentina ' s president adopt ##s boy to end werewolf curse [SEP] an airline passenger headed to dallas was removed from a plane at la guard ##ia airport on christmas eve because he raged after workers wished him a merry christmas , the new york post reports . the man was waiting to board american airlines flight 114 ##0 to dallas when a gate agent began welcoming everyone with the yu ##let ##ide greeting . he yelled at the woman , “ you shouldn ’ t say that because not everyone celebrates christmas . ” once on the plane , a flight attendant wished him a “ merry christmas . ” he yelled , “ don ’ t say , ‘ merry christmas ! ’ ” [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 5619 1005 1055 2343 11092 2015 2879 2000 2203 12797 8364 102 2019 8582 4628 3753 2000 5759 2001 3718 2013 1037 4946 2012 2474 3457 2401 3199 2006 4234 6574 2138 2002 28374 2044 3667 6257 2032 1037 12831 4234 1010 1996 2047 2259 2695 4311 1012 1996 2158 2001 3403 2000 2604 2137 7608 3462 12457 2692 2000 5759 2043 1037 4796 4005 2211 18066 3071 2007 1996 9805 7485 5178 14806 1012 2002 7581 2012 1996 2450 1010 1523 2017 5807 1521 1056 2360 2008 2138 2025 3071 21566 4234 1012 1524 2320 2006 1996 4946 1010 1037 3462 16742 6257 2032 1037 1523 12831 4234 1012 1524 2002 7581 1010 1523 2123 1521 1056 2360 1010 1520 12831 4234 999 1521 1524 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 5619 1005 1055 2343 11092 2015 2879 2000 2203 12797 8364 102 2019 8582 4628 3753 2000 5759 2001 3718 2013 1037 4946 2012 2474 3457 2401 3199 2006 4234 6574 2138 2002 28374 2044 3667 6257 2032 1037 12831 4234 1010 1996 2047 2259 2695 4311 1012 1996 2158 2001 3403 2000 2604 2137 7608 3462 12457 2692 2000 5759 2043 1037 4796 4005 2211 18066 3071 2007 1996 9805 7485 5178 14806 1012 2002 7581 2012 1996 2450 1010 1523 2017 5807 1521 1056 2360 2008 2138 2025 3071 21566 4234 1012 1524 2320 2006 1996 4946 1010 1037 3462 16742 6257 2032 1037 1523 12831 4234 1012 1524 2002 7581 1010 1523 2123 1521 1056 2360 1010 1520 12831 4234 999 1521 1524 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 3 (id = 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 3 (id = 3)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 25413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 25413\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 25413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 25413\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPK-4cw-gbz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "\n",
        "  bert_module = hub.Module(\n",
        "      BERT_MODEL_HUB,\n",
        "      trainable=True)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "  # Use \"sequence_outputs\" for token-level output.\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  # Create our own layer to tune for politeness data.\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "\n",
        "    # Dropout helps prevent overfitting\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "    \n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    # Convert labels into one-hot encoding\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "    if is_predicting:\n",
        "      return (predicted_labels, log_probs)\n",
        "\n",
        "    # If we're train/eval, compute loss between predicted and actual label\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "    return (loss, predicted_labels, log_probs)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6psSKF-ibrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_fn_builder actually creates our model function\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\n",
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "    # TRAIN and EVAL\n",
        "    if not is_predicting:\n",
        "\n",
        "      (loss, predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      train_op = bert.optimization.create_optimizer(\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "      # Calculate evaluation metrics. \n",
        "      def metric_fn(label_ids, predicted_labels):\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "        f1_score = tf.contrib.metrics.f1_score(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        auc = tf.metrics.auc(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        recall = tf.metrics.recall(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        precision = tf.metrics.precision(\n",
        "            label_ids,\n",
        "            predicted_labels) \n",
        "        true_pos = tf.metrics.true_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        true_neg = tf.metrics.true_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)   \n",
        "        false_pos = tf.metrics.false_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)  \n",
        "        false_neg = tf.metrics.false_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"f1_score\": f1_score,\n",
        "            \"auc\": auc,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"true_positives\": true_pos,\n",
        "            \"true_negatives\": true_neg,\n",
        "            \"false_positives\": false_pos,\n",
        "            \"false_negatives\": false_neg\n",
        "        }\n",
        "\n",
        "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "          loss=loss,\n",
        "          train_op=train_op)\n",
        "      else:\n",
        "          return tf.estimator.EstimatorSpec(mode=mode,\n",
        "            loss=loss,\n",
        "            eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      (predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      predictions = {\n",
        "          'probabilities': log_probs,\n",
        "          'labels': predicted_labels\n",
        "      }\n",
        "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "  # Return the actual model function in the closure\n",
        "  return model_fn"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UsOSS8Xjlt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute train and warmup steps from batch size\n",
        "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 3.0\n",
        "# Warmup is a period of time where hte learning rate \n",
        "# is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 500\n",
        "SAVE_SUMMARY_STEPS = 100"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K113qvz_jpJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute # train and warmup steps from batch size\n",
        "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGQxfu7IkACX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OUTPUT_DIR = './output'"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwNNDUD8j3TQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify outpit directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoB2P7c0j5nV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "8affa4d8-a216-4cf9-95bc-2568e6b701ac"
      },
      "source": [
        "model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "  model_fn=model_fn,\n",
        "  config=run_config,\n",
        "  params={\"batch_size\": BATCH_SIZE})"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': './output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f83f17ceeb8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': './output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f83f17ceeb8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQFVSySskHJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an input function for training. drop_remainder = True for using TPUs.\n",
        "train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh_uydVLkM3S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "578ccba3-b1ea-4fa7-a309-81eb166f1df0"
      },
      "source": [
        "print(f'Beginning Training!')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print(\"Training took time \", datetime.now() - current_time)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Training!\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-18-1fb5aeda3c8e>:34: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-18-1fb5aeda3c8e>:34: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/metrics/python/metrics/classification.py:162: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/metrics/python/metrics/classification.py:162: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into ./output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into ./output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 1.3769069, step = 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 1.3769069, step = 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.01092\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.01092\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.41665447, step = 100 (98.923 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.41665447, step = 100 (98.923 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13671\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13671\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.2804857, step = 200 (87.972 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.2804857, step = 200 (87.972 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13481\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13481\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.2827003, step = 300 (88.120 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.2827003, step = 300 (88.120 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13429\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13429\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.16446453, step = 400 (88.161 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.16446453, step = 400 (88.161 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 500 into ./output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 500 into ./output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.06129\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.06129\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.20145322, step = 500 (94.227 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.20145322, step = 500 (94.227 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13402\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13402\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.109214865, step = 600 (88.182 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.109214865, step = 600 (88.182 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13398\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13398\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.08591248, step = 700 (88.183 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.08591248, step = 700 (88.183 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13574\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13574\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.10913807, step = 800 (88.050 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.10913807, step = 800 (88.050 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13418\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13418\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.19279498, step = 900 (88.169 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.19279498, step = 900 (88.169 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 1000 into ./output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 1000 into ./output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.06236\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.06236\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.06883468, step = 1000 (94.129 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.06883468, step = 1000 (94.129 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13387\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13387\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.12396385, step = 1100 (88.195 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.12396385, step = 1100 (88.195 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13406\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.053529035, step = 1200 (88.178 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.053529035, step = 1200 (88.178 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13318\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13318\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.023748687, step = 1300 (88.247 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.023748687, step = 1300 (88.247 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13507\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13507\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0044902544, step = 1400 (88.101 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0044902544, step = 1400 (88.101 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 1500 into ./output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 1500 into ./output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.0627\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.0627\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.008994105, step = 1500 (94.097 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.008994105, step = 1500 (94.097 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.1333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.1333\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0013885592, step = 1600 (88.239 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0013885592, step = 1600 (88.239 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13285\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13285\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.115542546, step = 1700 (88.273 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.115542546, step = 1700 (88.273 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13762\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13762\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.117941394, step = 1800 (87.903 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.117941394, step = 1800 (87.903 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13706\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13706\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.11648231, step = 1900 (87.945 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.11648231, step = 1900 (87.945 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 2000 into ./output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 2000 into ./output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.06099\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.06099\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.02759827, step = 2000 (94.252 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.02759827, step = 2000 (94.252 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13317\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13317\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.011122799, step = 2100 (88.246 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.011122799, step = 2100 (88.246 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13402\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13402\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.016263472, step = 2200 (88.182 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.016263472, step = 2200 (88.182 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13674\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13674\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0015378979, step = 2300 (87.970 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0015378979, step = 2300 (87.970 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13567\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13567\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0035493777, step = 2400 (88.057 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0035493777, step = 2400 (88.057 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 2500 into ./output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 2500 into ./output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.06054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.06054\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.045599543, step = 2500 (94.289 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.045599543, step = 2500 (94.289 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.1331\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.1331\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.009485176, step = 2600 (88.255 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.009485176, step = 2600 (88.255 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13358\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13358\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.003954605, step = 2700 (88.215 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.003954605, step = 2700 (88.215 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13738\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13738\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0011664679, step = 2800 (87.923 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0011664679, step = 2800 (87.923 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13593\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13593\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.002090556, step = 2900 (88.032 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.002090556, step = 2900 (88.032 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 3000 into ./output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 3000 into ./output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.06206\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.06206\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.004644338, step = 3000 (94.157 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.004644338, step = 3000 (94.157 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13257\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13257\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.00056408765, step = 3100 (88.295 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.00056408765, step = 3100 (88.295 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13391\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13391\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.03315794, step = 3200 (88.191 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.03315794, step = 3200 (88.191 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13445\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.00166124, step = 3300 (88.150 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.00166124, step = 3300 (88.150 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13436\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13436\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.00036711627, step = 3400 (88.153 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.00036711627, step = 3400 (88.153 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 3500 into ./output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 3500 into ./output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.0602\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.0602\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0017051296, step = 3500 (94.320 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0017051296, step = 3500 (94.320 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13311\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13311\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.004246678, step = 3600 (88.253 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.004246678, step = 3600 (88.253 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13511\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13511\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0017717045, step = 3700 (88.098 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0017717045, step = 3700 (88.098 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13549\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13549\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0026348743, step = 3800 (88.067 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0026348743, step = 3800 (88.067 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13382\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13382\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0005515737, step = 3900 (88.200 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0005515737, step = 3900 (88.200 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 4000 into ./output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 4000 into ./output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.06291\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.06291\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0003014322, step = 4000 (94.081 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0003014322, step = 4000 (94.081 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13377\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13377\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0003788502, step = 4100 (88.199 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0003788502, step = 4100 (88.199 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13447\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13447\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.00037522695, step = 4200 (88.150 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.00037522695, step = 4200 (88.150 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13624\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13624\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0008166594, step = 4300 (88.009 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0008166594, step = 4300 (88.009 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13505\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13505\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.00053115276, step = 4400 (88.101 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.00053115276, step = 4400 (88.101 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 4500 into ./output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 4500 into ./output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.05879\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.05879\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0003513462, step = 4500 (94.447 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0003513462, step = 4500 (94.447 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.13406\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.00053392345, step = 4600 (88.180 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.00053392345, step = 4600 (88.180 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 4684 into ./output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 4684 into ./output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.0005321223.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.0005321223.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training took time  1:11:23.206364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnESM3OwkPiG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# converting test data to test input features in a format which BERT accepts\n",
        "test_input_fn = run_classifier.input_fn_builder(\n",
        "    features=test_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJQkwGLa1woO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predictions on test set\n",
        "predictions_test = estimator.predict(test_input_fn)\n",
        "# result list\n",
        "res_test = []\n",
        "for p in predictions_test:\n",
        "  res_test.append(p['labels'])\n",
        "\n",
        "pred_test = np.array(res_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqJDfeaR0AGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predictions on test set\n",
        "predictions_train = estimator.predict(train_input_fn)\n",
        "# result list\n",
        "res_train = []\n",
        "for p in predictions_train:\n",
        "  res_train.append(p['labels'])\n",
        "\n",
        "pred_train = np.array(res_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYu3tvTN85aB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculating accuracy score\n",
        "def acc_score(pred, actual):\n",
        "  cor = 0\n",
        "  for i in range(len(pred)):\n",
        "    if(pred[i] == actual[i]):\n",
        "      cor+=1\n",
        "  return(cor/len(pred))"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KkbMyWQzdCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# accuracy and f1 score\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
        "print(\"test accuracy {}\".format(accuracy_score(y_true = y_test, y_pred = pred_test)))\n",
        "print(\"test F1 score {}\".format(f1_score(y_true = y_test, y_pred = pred_test, average='weighted')))\n",
        "\n",
        "print(\"train accuracy {}\".format(accuracy_score(y_true = y[:377472], y_pred = pred_train)))\n",
        "print(\"train F1 score {}\".format(f1_score(y_true = y_train, y_pred = pred_train, average='weighted')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OL5eZjz-0nx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# unlabeled stances and bodies\n",
        "class unlab_DataSet():\n",
        "    def __init__(self, name, path=\"FakeNewsChallenge/fnc-1\"):\n",
        "        self.path = path\n",
        "\n",
        "        print(\"Reading test dataset\")\n",
        "        bodies = name+\"_bodies.csv\"\n",
        "        stances = name+\"_stances_unlabeled.csv\"\n",
        "        print(stances)\n",
        "\n",
        "        self.stances = self.read(stances)\n",
        "        articles = self.read(bodies)\n",
        "        self.articles = dict()\n",
        "\n",
        "        #make the body ID an integer value\n",
        "        for s in self.stances:\n",
        "            s['Body ID'] = int(s['Body ID'])\n",
        "\n",
        "        #copy all bodies into a dictionary\n",
        "        for article in articles:\n",
        "            self.articles[int(article['Body ID'])] = article['articleBody']\n",
        "\n",
        "        print(\"Total stances: \" + str(len(self.stances)))\n",
        "        print(\"Total bodies: \" + str(len(self.articles)))\n",
        "        \n",
        "    def read(self,filename):\n",
        "        rows = []\n",
        "        with open(self.path + \"/\" + filename, \"r\", encoding='utf-8') as table:\n",
        "            r = DictReader(table)\n",
        "\n",
        "            for line in r:\n",
        "                rows.append(line)\n",
        "        return rows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xgy8O4f_4JO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "478e5864-213b-47fb-d648-322b2166e990"
      },
      "source": [
        "# load file \n",
        "competition_test = unlab_DataSet(\"competition_test\")\n",
        "unlab_h = []\n",
        "unlab_b = []\n",
        "for s in competition_test.stances:\n",
        "  unlab_h.append(s['Headline'])\n",
        "  unlab_b.append(competition_test.articles[s['Body ID']])\n",
        "\n",
        "# dataframe\n",
        "unlab_df = pd.DataFrame(columns= ['head', 'body'])\n",
        "unlab_df['head'] = unlab_h\n",
        "unlab_df['body'] = unlab_b\n",
        "unlab_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading test dataset\n",
            "competition_test_stances_unlabeled.csv\n",
            "Total stances: 25413\n",
            "Total bodies: 904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUzM4so-vkEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get predictions \n",
        "def getPrediction(head, body):\n",
        "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = h, text_b = b, label = 0) for h,b in zip(head,body)] # here, \"\" is just a dummy label\n",
        "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
        "  predictions = estimator.predict(predict_input_fn)\n",
        "  return [(h, b, LABELS[prediction['labels']]) for h,b, prediction in zip(head,body, predictions)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3201YpavmWZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d8d82c9-1b8a-44d4-a6ea-5c25d221e3a8"
      },
      "source": [
        "# getting predictions for unlabelled data\n",
        "predictions = getPrediction(unlab_h, unlab_b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 25413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 25413\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] ferguson riots : pregnant woman loses eye after cops fire bean bag round through car window [SEP] a respected senior french police officer investigating the charlie he ##b ##do magazine massacre took his own life mere hours after the horrific attacks stunned the world . commissioner he ##lr ##ic fred ##ou , 45 , turned a gun on himself in his police office in limo ##ges last wednesday night , reported france 3 . a colleague found his body at 1a ##m on thursday , the day after three gunmen fired at the satirical magazine ' s office and left 12 people dead . speaking to our sister publication mirror online , the union of commissioners of the national police confirmed mr fred ##ou had taken [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] ferguson riots : pregnant woman loses eye after cops fire bean bag round through car window [SEP] a respected senior french police officer investigating the charlie he ##b ##do magazine massacre took his own life mere hours after the horrific attacks stunned the world . commissioner he ##lr ##ic fred ##ou , 45 , turned a gun on himself in his police office in limo ##ges last wednesday night , reported france 3 . a colleague found his body at 1a ##m on thursday , the day after three gunmen fired at the satirical magazine ' s office and left 12 people dead . speaking to our sister publication mirror online , the union of commissioners of the national police confirmed mr fred ##ou had taken [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 11262 12925 1024 6875 2450 12386 3239 2044 10558 2543 14068 4524 2461 2083 2482 3332 102 1037 9768 3026 2413 2610 2961 11538 1996 4918 2002 2497 3527 2932 9288 2165 2010 2219 2166 8210 2847 2044 1996 23512 4491 9860 1996 2088 1012 5849 2002 20974 2594 5965 7140 1010 3429 1010 2357 1037 3282 2006 2370 1999 2010 2610 2436 1999 23338 8449 2197 9317 2305 1010 2988 2605 1017 1012 1037 11729 2179 2010 2303 2012 20720 2213 2006 9432 1010 1996 2154 2044 2093 28932 5045 2012 1996 17251 2932 1005 1055 2436 1998 2187 2260 2111 2757 1012 4092 2000 2256 2905 4772 5259 3784 1010 1996 2586 1997 12396 1997 1996 2120 2610 4484 2720 5965 7140 2018 2579 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 11262 12925 1024 6875 2450 12386 3239 2044 10558 2543 14068 4524 2461 2083 2482 3332 102 1037 9768 3026 2413 2610 2961 11538 1996 4918 2002 2497 3527 2932 9288 2165 2010 2219 2166 8210 2847 2044 1996 23512 4491 9860 1996 2088 1012 5849 2002 20974 2594 5965 7140 1010 3429 1010 2357 1037 3282 2006 2370 1999 2010 2610 2436 1999 23338 8449 2197 9317 2305 1010 2988 2605 1017 1012 1037 11729 2179 2010 2303 2012 20720 2213 2006 9432 1010 1996 2154 2044 2093 28932 5045 2012 1996 17251 2932 1005 1055 2436 1998 2187 2260 2111 2757 1012 4092 2000 2256 2905 4772 5259 3784 1010 1996 2586 1997 12396 1997 1996 2120 2610 4484 2720 5965 7140 2018 2579 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] crazy conservatives are sure a gi ##tm ##o det ##aine ##e killed james foley [SEP] dave mori ##n ' s social networking company path is reportedly in apple inc . ' s acquisition path . apple inc . is close to buying social network path as it aims to bo ##lster its social media efforts , pan ##do ##dai ##ly reported , citing an internal source on apple ' s engineering team . the purchase would be more than an ac ##qui ##hire , the process when a company buys a company for its talent rather than its product . path ' s platform will probably survive the acquisition and somehow be incorporated into apple ' s rev ##amp ##ed messages app , according to the [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] crazy conservatives are sure a gi ##tm ##o det ##aine ##e killed james foley [SEP] dave mori ##n ' s social networking company path is reportedly in apple inc . ' s acquisition path . apple inc . is close to buying social network path as it aims to bo ##lster its social media efforts , pan ##do ##dai ##ly reported , citing an internal source on apple ' s engineering team . the purchase would be more than an ac ##qui ##hire , the process when a company buys a company for its talent rather than its product . path ' s platform will probably survive the acquisition and somehow be incorporated into apple ' s rev ##amp ##ed messages app , according to the [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4689 11992 2024 2469 1037 21025 21246 2080 20010 18175 2063 2730 2508 17106 102 4913 22993 2078 1005 1055 2591 14048 2194 4130 2003 7283 1999 6207 4297 1012 1005 1055 7654 4130 1012 6207 4297 1012 2003 2485 2000 9343 2591 2897 4130 2004 2009 8704 2000 8945 29576 2049 2591 2865 4073 1010 6090 3527 21351 2135 2988 1010 8951 2019 4722 3120 2006 6207 1005 1055 3330 2136 1012 1996 5309 2052 2022 2062 2084 2019 9353 15549 20908 1010 1996 2832 2043 1037 2194 23311 1037 2194 2005 2049 5848 2738 2084 2049 4031 1012 4130 1005 1055 4132 2097 2763 5788 1996 7654 1998 5064 2022 5100 2046 6207 1005 1055 7065 16613 2098 7696 10439 1010 2429 2000 1996 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4689 11992 2024 2469 1037 21025 21246 2080 20010 18175 2063 2730 2508 17106 102 4913 22993 2078 1005 1055 2591 14048 2194 4130 2003 7283 1999 6207 4297 1012 1005 1055 7654 4130 1012 6207 4297 1012 2003 2485 2000 9343 2591 2897 4130 2004 2009 8704 2000 8945 29576 2049 2591 2865 4073 1010 6090 3527 21351 2135 2988 1010 8951 2019 4722 3120 2006 6207 1005 1055 3330 2136 1012 1996 5309 2052 2022 2062 2084 2019 9353 15549 20908 1010 1996 2832 2043 1037 2194 23311 1037 2194 2005 2049 5848 2738 2084 2049 4031 1012 4130 1005 1055 4132 2097 2763 5788 1996 7654 1998 5064 2022 5100 2046 6207 1005 1055 7065 16613 2098 7696 10439 1010 2429 2000 1996 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] a russian guy says his justin bi ##eber ring ##tone saved him from a bear attack [SEP] a be ##rea ##ved afghan mother took revenge on the taliban after watching them kill her son in an ambush . reza gu ##l killed 25 taliban fighters and injured five others in a seven - hour gun ##bat ##tle in far ##ah province . gu ##l , who was joined by her daughter and daughter in - law , engaged the taliban using ak - 47 ##s and grenades , despite ##ne ##ver before having used a weapon . the em ##bat ##tled mother told to ##lo news , a 24 - hour afghan news broadcaster , she was awakened by shots early tuesday . after seeing that [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] a russian guy says his justin bi ##eber ring ##tone saved him from a bear attack [SEP] a be ##rea ##ved afghan mother took revenge on the taliban after watching them kill her son in an ambush . reza gu ##l killed 25 taliban fighters and injured five others in a seven - hour gun ##bat ##tle in far ##ah province . gu ##l , who was joined by her daughter and daughter in - law , engaged the taliban using ak - 47 ##s and grenades , despite ##ne ##ver before having used a weapon . the em ##bat ##tled mother told to ##lo news , a 24 - hour afghan news broadcaster , she was awakened by shots early tuesday . after seeing that [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1037 2845 3124 2758 2010 6796 12170 22669 3614 5524 5552 2032 2013 1037 4562 2886 102 1037 2022 16416 7178 12632 2388 2165 7195 2006 1996 16597 2044 3666 2068 3102 2014 2365 1999 2019 15283 1012 26323 19739 2140 2730 2423 16597 7299 1998 5229 2274 2500 1999 1037 2698 1011 3178 3282 14479 9286 1999 2521 4430 2874 1012 19739 2140 1010 2040 2001 2587 2011 2014 2684 1998 2684 1999 1011 2375 1010 5117 1996 16597 2478 17712 1011 4700 2015 1998 21914 1010 2750 2638 6299 2077 2383 2109 1037 5195 1012 1996 7861 14479 14782 2388 2409 2000 4135 2739 1010 1037 2484 1011 3178 12632 2739 11995 1010 2016 2001 20256 2011 7171 2220 9857 1012 2044 3773 2008 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1037 2845 3124 2758 2010 6796 12170 22669 3614 5524 5552 2032 2013 1037 4562 2886 102 1037 2022 16416 7178 12632 2388 2165 7195 2006 1996 16597 2044 3666 2068 3102 2014 2365 1999 2019 15283 1012 26323 19739 2140 2730 2423 16597 7299 1998 5229 2274 2500 1999 1037 2698 1011 3178 3282 14479 9286 1999 2521 4430 2874 1012 19739 2140 1010 2040 2001 2587 2011 2014 2684 1998 2684 1999 1011 2375 1010 5117 1996 16597 2478 17712 1011 4700 2015 1998 21914 1010 2750 2638 6299 2077 2383 2109 1037 5195 1012 1996 7861 14479 14782 2388 2409 2000 4135 2739 1010 1037 2484 1011 3178 12632 2739 11995 1010 2016 2001 20256 2011 7171 2220 9857 1012 2044 3773 2008 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] zombie cat : buried kitty believed dead , me ##ows back to life [SEP] he ##wl ##ett - packard is officially splitting in two . following rumors over the weekend , hp is announcing today that it will separate its pc and printer division from its enterprise and services business . the split means current ceo meg whitman will become the chairman of the pc and printer operation , and continue as ceo of the split - off enterprise business . dion wei ##sler , an executive at hp ’ s pc business , will take over as ceo of the company ’ s pc and printer operation . hp enterprise is the newly split - off part of the original company , and hp inc [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] zombie cat : buried kitty believed dead , me ##ows back to life [SEP] he ##wl ##ett - packard is officially splitting in two . following rumors over the weekend , hp is announcing today that it will separate its pc and printer division from its enterprise and services business . the split means current ceo meg whitman will become the chairman of the pc and printer operation , and continue as ceo of the split - off enterprise business . dion wei ##sler , an executive at hp ’ s pc business , will take over as ceo of the company ’ s pc and printer operation . hp enterprise is the newly split - off part of the original company , and hp inc [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 11798 4937 1024 3950 14433 3373 2757 1010 2033 15568 2067 2000 2166 102 2002 13668 6582 1011 24100 2003 3985 14541 1999 2048 1012 2206 11256 2058 1996 5353 1010 6522 2003 13856 2651 2008 2009 2097 3584 2049 7473 1998 15041 2407 2013 2049 6960 1998 2578 2449 1012 1996 3975 2965 2783 5766 12669 21311 2097 2468 1996 3472 1997 1996 7473 1998 15041 3169 1010 1998 3613 2004 5766 1997 1996 3975 1011 2125 6960 2449 1012 19542 11417 20590 1010 2019 3237 2012 6522 1521 1055 7473 2449 1010 2097 2202 2058 2004 5766 1997 1996 2194 1521 1055 7473 1998 15041 3169 1012 6522 6960 2003 1996 4397 3975 1011 2125 2112 1997 1996 2434 2194 1010 1998 6522 4297 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 11798 4937 1024 3950 14433 3373 2757 1010 2033 15568 2067 2000 2166 102 2002 13668 6582 1011 24100 2003 3985 14541 1999 2048 1012 2206 11256 2058 1996 5353 1010 6522 2003 13856 2651 2008 2009 2097 3584 2049 7473 1998 15041 2407 2013 2049 6960 1998 2578 2449 1012 1996 3975 2965 2783 5766 12669 21311 2097 2468 1996 3472 1997 1996 7473 1998 15041 3169 1010 1998 3613 2004 5766 1997 1996 3975 1011 2125 6960 2449 1012 19542 11417 20590 1010 2019 3237 2012 6522 1521 1055 7473 2449 1010 2097 2202 2058 2004 5766 1997 1996 2194 1521 1055 7473 1998 15041 3169 1012 6522 6960 2003 1996 4397 3975 1011 2125 2112 1997 1996 2434 2194 1010 1998 6522 4297 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] argentina ' s president adopt ##s boy to end werewolf curse [SEP] an airline passenger headed to dallas was removed from a plane at la guard ##ia airport on christmas eve because he raged after workers wished him a merry christmas , the new york post reports . the man was waiting to board american airlines flight 114 ##0 to dallas when a gate agent began welcoming everyone with the yu ##let ##ide greeting . he yelled at the woman , “ you shouldn ’ t say that because not everyone celebrates christmas . ” once on the plane , a flight attendant wished him a “ merry christmas . ” he yelled , “ don ’ t say , ‘ merry christmas ! ’ ” [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] argentina ' s president adopt ##s boy to end werewolf curse [SEP] an airline passenger headed to dallas was removed from a plane at la guard ##ia airport on christmas eve because he raged after workers wished him a merry christmas , the new york post reports . the man was waiting to board american airlines flight 114 ##0 to dallas when a gate agent began welcoming everyone with the yu ##let ##ide greeting . he yelled at the woman , “ you shouldn ’ t say that because not everyone celebrates christmas . ” once on the plane , a flight attendant wished him a “ merry christmas . ” he yelled , “ don ’ t say , ‘ merry christmas ! ’ ” [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 5619 1005 1055 2343 11092 2015 2879 2000 2203 12797 8364 102 2019 8582 4628 3753 2000 5759 2001 3718 2013 1037 4946 2012 2474 3457 2401 3199 2006 4234 6574 2138 2002 28374 2044 3667 6257 2032 1037 12831 4234 1010 1996 2047 2259 2695 4311 1012 1996 2158 2001 3403 2000 2604 2137 7608 3462 12457 2692 2000 5759 2043 1037 4796 4005 2211 18066 3071 2007 1996 9805 7485 5178 14806 1012 2002 7581 2012 1996 2450 1010 1523 2017 5807 1521 1056 2360 2008 2138 2025 3071 21566 4234 1012 1524 2320 2006 1996 4946 1010 1037 3462 16742 6257 2032 1037 1523 12831 4234 1012 1524 2002 7581 1010 1523 2123 1521 1056 2360 1010 1520 12831 4234 999 1521 1524 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 5619 1005 1055 2343 11092 2015 2879 2000 2203 12797 8364 102 2019 8582 4628 3753 2000 5759 2001 3718 2013 1037 4946 2012 2474 3457 2401 3199 2006 4234 6574 2138 2002 28374 2044 3667 6257 2032 1037 12831 4234 1010 1996 2047 2259 2695 4311 1012 1996 2158 2001 3403 2000 2604 2137 7608 3462 12457 2692 2000 5759 2043 1037 4796 4005 2211 18066 3071 2007 1996 9805 7485 5178 14806 1012 2002 7581 2012 1996 2450 1010 1523 2017 5807 1521 1056 2360 2008 2138 2025 3071 21566 4234 1012 1524 2320 2006 1996 4946 1010 1037 3462 16742 6257 2032 1037 1523 12831 4234 1012 1524 2002 7581 1010 1523 2123 1521 1056 2360 1010 1520 12831 4234 999 1521 1524 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 25413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 25413\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 25413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 25413\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./output/model.ckpt-4684\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./output/model.ckpt-4684\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2il-9SIEkef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# converting to numpy array\n",
        "res_un = np.array(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1_Nh48uFPNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataframe to store predicted stances\n",
        "df_res = pd.DataFrame(res_un, columns = ['Headline', 'body','Stance'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_RvLBf9FYf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataframe for answe\n",
        "df = pd.read_csv(\"FakeNewsChallenge/fnc-1/competition_test_stances_unlabeled.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp01UoD5HQ1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving to answer.csv\n",
        "df.to_csv('answer.csv', index=False, encoding='utf-8') # From pandas library"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}